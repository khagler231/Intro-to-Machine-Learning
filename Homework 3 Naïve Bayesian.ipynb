{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e8b2e953-cf39-4a2b-92fe-02ced412de33",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Kevin Hagler\n",
    "# Student ID: 801197095\n",
    "# Homework 3: Naïve Bayesian\n",
    "# Date: 10/25/2022"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89e24483-729f-4074-b977-dd0887a4a183",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import matplotlib.pyplot as plt \n",
    "import pandas as pd \n",
    "import seaborn as sns \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics \n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f59ffd58-2689-49e6-a4e7-4012c6731f69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.799e+01, 1.038e+01, 1.228e+02, ..., 2.654e-01, 4.601e-01,\n",
       "        1.189e-01],\n",
       "       [2.057e+01, 1.777e+01, 1.329e+02, ..., 1.860e-01, 2.750e-01,\n",
       "        8.902e-02],\n",
       "       [1.969e+01, 2.125e+01, 1.300e+02, ..., 2.430e-01, 3.613e-01,\n",
       "        8.758e-02],\n",
       "       ...,\n",
       "       [1.660e+01, 2.808e+01, 1.083e+02, ..., 1.418e-01, 2.218e-01,\n",
       "        7.820e-02],\n",
       "       [2.060e+01, 2.933e+01, 1.401e+02, ..., 2.650e-01, 4.087e-01,\n",
       "        1.240e-01],\n",
       "       [7.760e+00, 2.454e+01, 4.792e+01, ..., 0.000e+00, 2.871e-01,\n",
       "        7.039e-02]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# gathering cancer data\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "breast = load_breast_cancer() \n",
    "breast_data = breast.data \n",
    "breast_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aae43d4f-ff38-4dcb-bd10-51fffd21e755",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_input = pd.DataFrame(breast_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9ad89aa-a3b8-4925-99f0-16ecfcfa8be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "breast_labels = breast.target "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "66d7bed5-8a6c-4a42-a4b5-723c72895ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.reshape(breast_labels,(569,1))\n",
    "final_breast_data = np.concatenate([breast_data,labels],axis=1)\n",
    "breast_dataset = pd.DataFrame(final_breast_data) \n",
    "\n",
    "features = breast.feature_names \n",
    "breast_dataset.columns = np.append(features,'label') \n",
    "breast_dataset['label'].replace(0, 'Benign',inplace=True) \n",
    "breast_dataset['label'].replace(1, 'Malignant',inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "208091df-fb76-4358-a23a-aee0eb82cd03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>17.99</td>\n",
       "      <td>10.38</td>\n",
       "      <td>122.80</td>\n",
       "      <td>1001.0</td>\n",
       "      <td>0.11840</td>\n",
       "      <td>0.27760</td>\n",
       "      <td>0.30010</td>\n",
       "      <td>0.14710</td>\n",
       "      <td>0.2419</td>\n",
       "      <td>0.07871</td>\n",
       "      <td>...</td>\n",
       "      <td>17.33</td>\n",
       "      <td>184.60</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>0.16220</td>\n",
       "      <td>0.66560</td>\n",
       "      <td>0.7119</td>\n",
       "      <td>0.2654</td>\n",
       "      <td>0.4601</td>\n",
       "      <td>0.11890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20.57</td>\n",
       "      <td>17.77</td>\n",
       "      <td>132.90</td>\n",
       "      <td>1326.0</td>\n",
       "      <td>0.08474</td>\n",
       "      <td>0.07864</td>\n",
       "      <td>0.08690</td>\n",
       "      <td>0.07017</td>\n",
       "      <td>0.1812</td>\n",
       "      <td>0.05667</td>\n",
       "      <td>...</td>\n",
       "      <td>23.41</td>\n",
       "      <td>158.80</td>\n",
       "      <td>1956.0</td>\n",
       "      <td>0.12380</td>\n",
       "      <td>0.18660</td>\n",
       "      <td>0.2416</td>\n",
       "      <td>0.1860</td>\n",
       "      <td>0.2750</td>\n",
       "      <td>0.08902</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>19.69</td>\n",
       "      <td>21.25</td>\n",
       "      <td>130.00</td>\n",
       "      <td>1203.0</td>\n",
       "      <td>0.10960</td>\n",
       "      <td>0.15990</td>\n",
       "      <td>0.19740</td>\n",
       "      <td>0.12790</td>\n",
       "      <td>0.2069</td>\n",
       "      <td>0.05999</td>\n",
       "      <td>...</td>\n",
       "      <td>25.53</td>\n",
       "      <td>152.50</td>\n",
       "      <td>1709.0</td>\n",
       "      <td>0.14440</td>\n",
       "      <td>0.42450</td>\n",
       "      <td>0.4504</td>\n",
       "      <td>0.2430</td>\n",
       "      <td>0.3613</td>\n",
       "      <td>0.08758</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.42</td>\n",
       "      <td>20.38</td>\n",
       "      <td>77.58</td>\n",
       "      <td>386.1</td>\n",
       "      <td>0.14250</td>\n",
       "      <td>0.28390</td>\n",
       "      <td>0.24140</td>\n",
       "      <td>0.10520</td>\n",
       "      <td>0.2597</td>\n",
       "      <td>0.09744</td>\n",
       "      <td>...</td>\n",
       "      <td>26.50</td>\n",
       "      <td>98.87</td>\n",
       "      <td>567.7</td>\n",
       "      <td>0.20980</td>\n",
       "      <td>0.86630</td>\n",
       "      <td>0.6869</td>\n",
       "      <td>0.2575</td>\n",
       "      <td>0.6638</td>\n",
       "      <td>0.17300</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20.29</td>\n",
       "      <td>14.34</td>\n",
       "      <td>135.10</td>\n",
       "      <td>1297.0</td>\n",
       "      <td>0.10030</td>\n",
       "      <td>0.13280</td>\n",
       "      <td>0.19800</td>\n",
       "      <td>0.10430</td>\n",
       "      <td>0.1809</td>\n",
       "      <td>0.05883</td>\n",
       "      <td>...</td>\n",
       "      <td>16.67</td>\n",
       "      <td>152.20</td>\n",
       "      <td>1575.0</td>\n",
       "      <td>0.13740</td>\n",
       "      <td>0.20500</td>\n",
       "      <td>0.4000</td>\n",
       "      <td>0.1625</td>\n",
       "      <td>0.2364</td>\n",
       "      <td>0.07678</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>564</th>\n",
       "      <td>21.56</td>\n",
       "      <td>22.39</td>\n",
       "      <td>142.00</td>\n",
       "      <td>1479.0</td>\n",
       "      <td>0.11100</td>\n",
       "      <td>0.11590</td>\n",
       "      <td>0.24390</td>\n",
       "      <td>0.13890</td>\n",
       "      <td>0.1726</td>\n",
       "      <td>0.05623</td>\n",
       "      <td>...</td>\n",
       "      <td>26.40</td>\n",
       "      <td>166.10</td>\n",
       "      <td>2027.0</td>\n",
       "      <td>0.14100</td>\n",
       "      <td>0.21130</td>\n",
       "      <td>0.4107</td>\n",
       "      <td>0.2216</td>\n",
       "      <td>0.2060</td>\n",
       "      <td>0.07115</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>565</th>\n",
       "      <td>20.13</td>\n",
       "      <td>28.25</td>\n",
       "      <td>131.20</td>\n",
       "      <td>1261.0</td>\n",
       "      <td>0.09780</td>\n",
       "      <td>0.10340</td>\n",
       "      <td>0.14400</td>\n",
       "      <td>0.09791</td>\n",
       "      <td>0.1752</td>\n",
       "      <td>0.05533</td>\n",
       "      <td>...</td>\n",
       "      <td>38.25</td>\n",
       "      <td>155.00</td>\n",
       "      <td>1731.0</td>\n",
       "      <td>0.11660</td>\n",
       "      <td>0.19220</td>\n",
       "      <td>0.3215</td>\n",
       "      <td>0.1628</td>\n",
       "      <td>0.2572</td>\n",
       "      <td>0.06637</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>16.60</td>\n",
       "      <td>28.08</td>\n",
       "      <td>108.30</td>\n",
       "      <td>858.1</td>\n",
       "      <td>0.08455</td>\n",
       "      <td>0.10230</td>\n",
       "      <td>0.09251</td>\n",
       "      <td>0.05302</td>\n",
       "      <td>0.1590</td>\n",
       "      <td>0.05648</td>\n",
       "      <td>...</td>\n",
       "      <td>34.12</td>\n",
       "      <td>126.70</td>\n",
       "      <td>1124.0</td>\n",
       "      <td>0.11390</td>\n",
       "      <td>0.30940</td>\n",
       "      <td>0.3403</td>\n",
       "      <td>0.1418</td>\n",
       "      <td>0.2218</td>\n",
       "      <td>0.07820</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>567</th>\n",
       "      <td>20.60</td>\n",
       "      <td>29.33</td>\n",
       "      <td>140.10</td>\n",
       "      <td>1265.0</td>\n",
       "      <td>0.11780</td>\n",
       "      <td>0.27700</td>\n",
       "      <td>0.35140</td>\n",
       "      <td>0.15200</td>\n",
       "      <td>0.2397</td>\n",
       "      <td>0.07016</td>\n",
       "      <td>...</td>\n",
       "      <td>39.42</td>\n",
       "      <td>184.60</td>\n",
       "      <td>1821.0</td>\n",
       "      <td>0.16500</td>\n",
       "      <td>0.86810</td>\n",
       "      <td>0.9387</td>\n",
       "      <td>0.2650</td>\n",
       "      <td>0.4087</td>\n",
       "      <td>0.12400</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568</th>\n",
       "      <td>7.76</td>\n",
       "      <td>24.54</td>\n",
       "      <td>47.92</td>\n",
       "      <td>181.0</td>\n",
       "      <td>0.05263</td>\n",
       "      <td>0.04362</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.00000</td>\n",
       "      <td>0.1587</td>\n",
       "      <td>0.05884</td>\n",
       "      <td>...</td>\n",
       "      <td>30.37</td>\n",
       "      <td>59.16</td>\n",
       "      <td>268.6</td>\n",
       "      <td>0.08996</td>\n",
       "      <td>0.06444</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0.2871</td>\n",
       "      <td>0.07039</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>569 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "0          17.99         10.38          122.80     1001.0          0.11840   \n",
       "1          20.57         17.77          132.90     1326.0          0.08474   \n",
       "2          19.69         21.25          130.00     1203.0          0.10960   \n",
       "3          11.42         20.38           77.58      386.1          0.14250   \n",
       "4          20.29         14.34          135.10     1297.0          0.10030   \n",
       "..           ...           ...             ...        ...              ...   \n",
       "564        21.56         22.39          142.00     1479.0          0.11100   \n",
       "565        20.13         28.25          131.20     1261.0          0.09780   \n",
       "566        16.60         28.08          108.30      858.1          0.08455   \n",
       "567        20.60         29.33          140.10     1265.0          0.11780   \n",
       "568         7.76         24.54           47.92      181.0          0.05263   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "0             0.27760         0.30010              0.14710         0.2419   \n",
       "1             0.07864         0.08690              0.07017         0.1812   \n",
       "2             0.15990         0.19740              0.12790         0.2069   \n",
       "3             0.28390         0.24140              0.10520         0.2597   \n",
       "4             0.13280         0.19800              0.10430         0.1809   \n",
       "..                ...             ...                  ...            ...   \n",
       "564           0.11590         0.24390              0.13890         0.1726   \n",
       "565           0.10340         0.14400              0.09791         0.1752   \n",
       "566           0.10230         0.09251              0.05302         0.1590   \n",
       "567           0.27700         0.35140              0.15200         0.2397   \n",
       "568           0.04362         0.00000              0.00000         0.1587   \n",
       "\n",
       "     mean fractal dimension  ...  worst texture  worst perimeter  worst area  \\\n",
       "0                   0.07871  ...          17.33           184.60      2019.0   \n",
       "1                   0.05667  ...          23.41           158.80      1956.0   \n",
       "2                   0.05999  ...          25.53           152.50      1709.0   \n",
       "3                   0.09744  ...          26.50            98.87       567.7   \n",
       "4                   0.05883  ...          16.67           152.20      1575.0   \n",
       "..                      ...  ...            ...              ...         ...   \n",
       "564                 0.05623  ...          26.40           166.10      2027.0   \n",
       "565                 0.05533  ...          38.25           155.00      1731.0   \n",
       "566                 0.05648  ...          34.12           126.70      1124.0   \n",
       "567                 0.07016  ...          39.42           184.60      1821.0   \n",
       "568                 0.05884  ...          30.37            59.16       268.6   \n",
       "\n",
       "     worst smoothness  worst compactness  worst concavity  \\\n",
       "0             0.16220            0.66560           0.7119   \n",
       "1             0.12380            0.18660           0.2416   \n",
       "2             0.14440            0.42450           0.4504   \n",
       "3             0.20980            0.86630           0.6869   \n",
       "4             0.13740            0.20500           0.4000   \n",
       "..                ...                ...              ...   \n",
       "564           0.14100            0.21130           0.4107   \n",
       "565           0.11660            0.19220           0.3215   \n",
       "566           0.11390            0.30940           0.3403   \n",
       "567           0.16500            0.86810           0.9387   \n",
       "568           0.08996            0.06444           0.0000   \n",
       "\n",
       "     worst concave points  worst symmetry  worst fractal dimension  label  \n",
       "0                  0.2654          0.4601                  0.11890      0  \n",
       "1                  0.1860          0.2750                  0.08902      0  \n",
       "2                  0.2430          0.3613                  0.08758      0  \n",
       "3                  0.2575          0.6638                  0.17300      0  \n",
       "4                  0.1625          0.2364                  0.07678      0  \n",
       "..                    ...             ...                      ...    ...  \n",
       "564                0.2216          0.2060                  0.07115      0  \n",
       "565                0.1628          0.2572                  0.06637      0  \n",
       "566                0.1418          0.2218                  0.07820      0  \n",
       "567                0.2650          0.4087                  0.12400      0  \n",
       "568                0.0000          0.2871                  0.07039      1  \n",
       "\n",
       "[569 rows x 31 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Setting the label column to ones and zeros.\n",
    "varList = ['label']\n",
    "def binaryMap(x):\n",
    "    return x.map({'Malignant': 1, 'Benign': 0})\n",
    "\n",
    "breast_dataset[varList] = breast_dataset[varList].apply(binaryMap)\n",
    "data = breast_dataset\n",
    "breast_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "087b4fa7-3fa1-4906-9f5d-518f914fb1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting x and y values\n",
    "x = breast_dataset.iloc[:,0:29].values\n",
    "y = breast_dataset.iloc[:, [30]]\n",
    "#print(y)\n",
    "\n",
    "# Spliting data into 80% training and 20% testing\n",
    "np.random.seed(0)\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(x, y, train_size = 0.80, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "01b19690-b2eb-4293-b0f9-f813e15cbf7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# standardizing data set \n",
    "sc_X = StandardScaler() \n",
    "xTrain = sc_X.fit_transform(xTrain) \n",
    "xTest = sc_X.transform(xTest) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b080c842-7dbb-442a-b8fc-8f236f8583bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# Problem 1\n",
    "#############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bbd2c96-0d11-407f-b850-1eec5c2db508",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GaussianNB()\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.89      0.92       212\n",
      "           1       0.94      0.97      0.95       357\n",
      "\n",
      "    accuracy                           0.94       569\n",
      "   macro avg       0.94      0.93      0.94       569\n",
      "weighted avg       0.94      0.94      0.94       569\n",
      "\n",
      "[[189  23]\n",
      " [ 10 347]]\n"
     ]
    }
   ],
   "source": [
    "# Naive bayes model\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model = GaussianNB()\n",
    "\n",
    "model.fit(breast.data, breast.target)\n",
    "print(model)\n",
    "expected = breast.target\n",
    "predicted = model.predict(breast.data)\n",
    "print(metrics.classification_report(expected,predicted))\n",
    "print(metrics.confusion_matrix(expected,predicted))\n",
    "matrix = confusion_matrix(expected, predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2ca37041-e2db-4d0b-aace-d3070c90a72e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Text(0.5, 6.799999999999997, 'Predicted')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plotting the confusion matrix: prediction vs values\n",
    "fig, ax = plt.subplots()\n",
    "plt.tight_layout() \n",
    "# create heatmap \n",
    "sns.heatmap(pd.DataFrame(matrix),annot=True, cmap=\"YlGnBu\" ,fmt='g')\n",
    "ax.xaxis.set_label_position(\"top\") \n",
    "plt.title('GaussianNB Confusion matrix', y=1.1) \n",
    "plt.ylabel('Expected') \n",
    "plt.xlabel('Predicted') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c0266dd8-cae6-4701-9788-654b5bf82809",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# Problem 2\n",
    "#############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "08d4b4fb-4108-460b-91cd-76ea907a7257",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 1\n",
      "Accuracy = 0.9122807017543859\n",
      "Recall = 0.9552238805970149\n",
      "precision = 0.9014084507042254\n",
      "matrix :\n",
      "[[40  7]\n",
      " [ 3 64]]\n",
      "\n",
      "K: 2\n",
      "Accuracy = 0.9473684210526315\n",
      "Recall = 0.9701492537313433\n",
      "precision = 0.9420289855072463\n",
      "matrix :\n",
      "[[43  4]\n",
      " [ 2 65]]\n",
      "\n",
      "K: 3\n",
      "Accuracy = 0.9385964912280702\n",
      "Recall = 0.9552238805970149\n",
      "precision = 0.9411764705882353\n",
      "matrix :\n",
      "[[43  4]\n",
      " [ 3 64]]\n",
      "\n",
      "K: 4\n",
      "Accuracy = 0.9385964912280702\n",
      "Recall = 0.9253731343283582\n",
      "precision = 0.96875\n",
      "matrix :\n",
      "[[45  2]\n",
      " [ 5 62]]\n",
      "\n",
      "K: 5\n",
      "Accuracy = 0.9385964912280702\n",
      "Recall = 0.9253731343283582\n",
      "precision = 0.96875\n",
      "matrix :\n",
      "[[45  2]\n",
      " [ 5 62]]\n",
      "\n",
      "K: 6\n",
      "Accuracy = 0.9473684210526315\n",
      "Recall = 0.9253731343283582\n",
      "precision = 0.9841269841269841\n",
      "matrix :\n",
      "[[46  1]\n",
      " [ 5 62]]\n",
      "\n",
      "K: 7\n",
      "Accuracy = 0.9473684210526315\n",
      "Recall = 0.9253731343283582\n",
      "precision = 0.9841269841269841\n",
      "matrix :\n",
      "[[46  1]\n",
      " [ 5 62]]\n",
      "\n",
      "K: 8\n",
      "Accuracy = 0.9473684210526315\n",
      "Recall = 0.9253731343283582\n",
      "precision = 0.9841269841269841\n",
      "matrix :\n",
      "[[46  1]\n",
      " [ 5 62]]\n",
      "\n",
      "K: 9\n",
      "Accuracy = 0.9473684210526315\n",
      "Recall = 0.9253731343283582\n",
      "precision = 0.9841269841269841\n",
      "matrix :\n",
      "[[46  1]\n",
      " [ 5 62]]\n",
      "\n",
      "K: 10\n",
      "Accuracy = 0.9912280701754386\n",
      "Recall = 0.9850746268656716\n",
      "precision = 1.0\n",
      "matrix :\n",
      "[[47  0]\n",
      " [ 1 66]]\n",
      "\n",
      "K: 11\n",
      "Accuracy = 1.0\n",
      "Recall = 1.0\n",
      "precision = 1.0\n",
      "matrix :\n",
      "[[47  0]\n",
      " [ 0 67]]\n",
      "\n",
      "K: 12\n",
      "Accuracy = 1.0\n",
      "Recall = 1.0\n",
      "precision = 1.0\n",
      "matrix :\n",
      "[[47  0]\n",
      " [ 0 67]]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "for i in range (12):\n",
    "    n=i+1\n",
    "    pca = PCA(n)\n",
    "    breast3 = breast_dataset\n",
    "    breast3 = pca.fit_transform(breast3)\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(breast3, breast_labels, train_size = 0.80, test_size = 0.2, random_state = 0)\n",
    "    Classifier = LogisticRegression()\n",
    "    Classifier.fit(xTrain, yTrain)\n",
    "    prediction =  Classifier.predict(xTest)\n",
    "    matrix = confusion_matrix(yTest, prediction)\n",
    "    print(\"K:\",n)\n",
    "    print('Accuracy =', metrics.accuracy_score(yTest,prediction))\n",
    "    print('Recall =', metrics.recall_score(yTest,prediction))\n",
    "    print('precision =', metrics.precision_score(yTest,prediction))\n",
    "    print('matrix :')\n",
    "    print(matrix)\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "69042e74-3b88-4016-b4f9-65a42f950909",
   "metadata": {},
   "outputs": [],
   "source": [
    "#############\n",
    "# Problem 3\n",
    "#############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b706d308-4af7-4fd0-b06a-d72015d9da15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "K: 1\n",
      "Accuracy = 0.9032967032967033\n",
      "Recall = 0.9620689655172414\n",
      "precision = 0.8942307692307693\n",
      "\n",
      "K: 2\n",
      "Accuracy = 0.9274725274725275\n",
      "Recall = 0.9655172413793104\n",
      "precision = 0.9240924092409241\n",
      "\n",
      "K: 3\n",
      "Accuracy = 0.9296703296703297\n",
      "Recall = 0.9620689655172414\n",
      "precision = 0.93\n",
      "\n",
      "K: 4\n",
      "Accuracy = 0.9582417582417583\n",
      "Recall = 0.9758620689655172\n",
      "precision = 0.9593220338983051\n",
      "\n",
      "K: 5\n",
      "Accuracy = 0.9560439560439561\n",
      "Recall = 0.9724137931034482\n",
      "precision = 0.9591836734693877\n",
      "\n",
      "K: 6\n",
      "Accuracy = 0.9582417582417583\n",
      "Recall = 0.9724137931034482\n",
      "precision = 0.962457337883959\n",
      "\n",
      "K: 7\n",
      "Accuracy = 0.9560439560439561\n",
      "Recall = 0.9689655172413794\n",
      "precision = 0.9623287671232876\n",
      "\n",
      "K: 8\n",
      "Accuracy = 0.9560439560439561\n",
      "Recall = 0.9689655172413794\n",
      "precision = 0.9623287671232876\n",
      "\n",
      "K: 9\n",
      "Accuracy = 0.9582417582417583\n",
      "Recall = 0.9689655172413794\n",
      "precision = 0.9656357388316151\n",
      "\n",
      "K: 10\n",
      "Accuracy = 0.9956043956043956\n",
      "Recall = 1.0\n",
      "precision = 0.9931506849315068\n",
      "\n",
      "K: 11\n",
      "Accuracy = 0.9978021978021978\n",
      "Recall = 1.0\n",
      "precision = 0.9965635738831615\n",
      "\n",
      "K: 12\n",
      "Accuracy = 0.9978021978021978\n",
      "Recall = 1.0\n",
      "precision = 0.9965635738831615\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "for i in range (12):\n",
    "    n=i+1\n",
    "    pca = PCA(n)\n",
    "    breast2 = breast_dataset\n",
    "    breast2 = pca.fit_transform(breast2)\n",
    "    xTrain, xTest, yTrain, yTest = train_test_split(breast2, breast_labels, train_size = 0.80, test_size = 0.2, random_state = 0)\n",
    "    Classifier = LogisticRegression()\n",
    "    Classifier.fit(xTrain, yTrain)\n",
    "    prediction =  Classifier.predict(xTrain)\n",
    "    model = GaussianNB()\n",
    "    model.fit(xTrain,yTrain)\n",
    "    print(\"K:\",n)\n",
    "    print('Accuracy =', metrics.accuracy_score(yTrain,prediction))\n",
    "    print('Recall =', metrics.recall_score(yTrain,prediction))\n",
    "    print('precision =', metrics.precision_score(yTrain,prediction))\n",
    "    print(\"\")\n",
    "   "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
